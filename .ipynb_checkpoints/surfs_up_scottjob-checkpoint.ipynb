{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///Resources/hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table name: measurement\n",
      "   id INTEGER  PRIMARY KEY\n",
      "   station TEXT\n",
      "   date TEXT\n",
      "   prcp FLOAT\n",
      "   tobs FLOAT\n",
      "Table name: station\n",
      "   id INTEGER  PRIMARY KEY\n",
      "   station TEXT\n",
      "   name TEXT\n",
      "   latitude FLOAT\n",
      "   longitude FLOAT\n",
      "   elevation FLOAT\n"
     ]
    }
   ],
   "source": [
    "# Show table names, columns, and data types\n",
    "for table in Base.classes:\n",
    "    print(f\"Table name: {table.__table__.name}\")\n",
    "    for c in table.__table__.columns:\n",
    "        print(f\"   {c.name} {c.type}\", end='')\n",
    "        if c.primary_key:\n",
    "            print(\"  PRIMARY KEY\")\n",
    "        else:\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "Meas = Base.classes.measurement\n",
    "Sta = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'USC00519397', 'WAIKIKI 717.2, HI US', 21.2716, -157.8168, 3.0),\n",
       " (2, 'USC00513117', 'KANEOHE 838.1, HI US', 21.4234, -157.8015, 14.6),\n",
       " (3, 'USC00514830', 'KUALOA RANCH HEADQUARTERS 886.9, HI US', 21.5213, -157.8374, 7.0),\n",
       " (4, 'USC00517948', 'PEARL CITY, HI US', 21.3934, -157.9751, 11.9),\n",
       " (5, 'USC00518838', 'UPPER WAHIAWA 874.3, HI US', 21.4992, -158.0111, 306.6),\n",
       " (6, 'USC00519523', 'WAIMANALO EXPERIMENTAL FARM, HI US', 21.33556, -157.71139, 19.5),\n",
       " (7, 'USC00519281', 'WAIHEE 837.5, HI US', 21.45167, -157.84888999999998, 32.9),\n",
       " (8, 'USC00511918', 'HONOLULU OBSERVATORY 702.2, HI US', 21.3152, -157.9992, 0.9),\n",
       " (9, 'USC00516128', 'MANOA LYON ARBO 785.2, HI US', 21.3331, -157.8025, 152.4)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute('SELECT * FROM station').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'USC00519397', '2010-01-01', 0.08, 65.0),\n",
       " (2, 'USC00519397', '2010-01-02', 0.0, 63.0),\n",
       " (3, 'USC00519397', '2010-01-03', 0.0, 74.0),\n",
       " (4, 'USC00519397', '2010-01-04', 0.0, 76.0),\n",
       " (5, 'USC00519397', '2010-01-06', None, 73.0),\n",
       " (6, 'USC00519397', '2010-01-07', 0.06, 70.0),\n",
       " (7, 'USC00519397', '2010-01-08', 0.0, 64.0),\n",
       " (8, 'USC00519397', '2010-01-09', 0.0, 68.0),\n",
       " (9, 'USC00519397', '2010-01-10', 0.0, 73.0),\n",
       " (10, 'USC00519397', '2010-01-11', 0.01, 64.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute('SELECT * FROM measurement LIMIT 10').fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_date</th>\n",
       "      <th>End_date</th>\n",
       "      <th>Obs_count</th>\n",
       "      <th>Date_diff</th>\n",
       "      <th>Pcnt_complete</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USC00511918</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2015-10-30</td>\n",
       "      <td>1979</td>\n",
       "      <td>2129</td>\n",
       "      <td>92.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USC00513117</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>2709</td>\n",
       "      <td>2769</td>\n",
       "      <td>97.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USC00514830</th>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>2202</td>\n",
       "      <td>2733</td>\n",
       "      <td>80.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USC00516128</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>2612</td>\n",
       "      <td>2792</td>\n",
       "      <td>93.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USC00517948</th>\n",
       "      <td>2010-05-03</td>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>1372</td>\n",
       "      <td>2647</td>\n",
       "      <td>51.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USC00518838</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2015-11-20</td>\n",
       "      <td>511</td>\n",
       "      <td>2150</td>\n",
       "      <td>23.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USC00519281</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>2772</td>\n",
       "      <td>2787</td>\n",
       "      <td>99.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USC00519397</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>2724</td>\n",
       "      <td>2792</td>\n",
       "      <td>97.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USC00519523</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2017-08-23</td>\n",
       "      <td>2669</td>\n",
       "      <td>2792</td>\n",
       "      <td>95.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Start_date   End_date  Obs_count  Date_diff  Pcnt_complete\n",
       "Station                                                               \n",
       "USC00511918 2010-01-01 2015-10-30       1979       2129          92.95\n",
       "USC00513117 2010-01-01 2017-07-31       2709       2769          97.83\n",
       "USC00514830 2010-03-01 2017-08-23       2202       2733          80.57\n",
       "USC00516128 2010-01-01 2017-08-23       2612       2792          93.55\n",
       "USC00517948 2010-05-03 2017-07-31       1372       2647          51.83\n",
       "USC00518838 2010-01-01 2015-11-20        511       2150          23.77\n",
       "USC00519281 2010-01-01 2017-08-18       2772       2787          99.46\n",
       "USC00519397 2010-01-01 2017-08-23       2724       2792          97.56\n",
       "USC00519523 2010-01-01 2017-08-23       2669       2792          95.59"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sel = [Meas.station, \n",
    "       func.min(Meas.date), \n",
    "       func.max(Meas.date),\n",
    "       func.count(Meas.date)]\n",
    "sta_daterange = session.query(*sel).\\\n",
    "    group_by(Meas.station).\\\n",
    "    order_by(Meas.station).all()\n",
    "cols = ['Station','Start_date','End_date', 'Obs_count']\n",
    "df_sta_dates = pd.DataFrame(sta_daterange, columns=cols)\n",
    "df_sta_dates['Start_date'] = pd.to_datetime(df_sta_dates['Start_date'])\n",
    "df_sta_dates['End_date'] = pd.to_datetime(df_sta_dates['End_date'])\n",
    "df_sta_dates['Date_diff'] = (df_sta_dates['End_date'] - df_sta_dates['Start_date']).dt.days + 1\n",
    "df_sta_dates['Pcnt_complete'] = round(df_sta_dates['Obs_count'] / df_sta_dates['Date_diff'] * 100, 2)\n",
    "df_sta_dates.set_index('Station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('USC00511918', '2010-01-01', '2015-10-30', 'HONOLULU OBSERVATORY 702.2, HI US'),\n",
       " ('USC00513117', '2010-01-01', '2017-07-31', 'KANEOHE 838.1, HI US'),\n",
       " ('USC00514830', '2010-03-01', '2017-08-23', 'KUALOA RANCH HEADQUARTERS 886.9, HI US'),\n",
       " ('USC00516128', '2010-01-01', '2017-08-23', 'MANOA LYON ARBO 785.2, HI US'),\n",
       " ('USC00517948', '2010-05-03', '2017-07-31', 'PEARL CITY, HI US'),\n",
       " ('USC00518838', '2010-01-01', '2015-11-20', 'UPPER WAHIAWA 874.3, HI US'),\n",
       " ('USC00519281', '2010-01-01', '2017-08-18', 'WAIHEE 837.5, HI US'),\n",
       " ('USC00519397', '2010-01-01', '2017-08-23', 'WAIKIKI 717.2, HI US'),\n",
       " ('USC00519523', '2010-01-01', '2017-08-23', 'WAIMANALO EXPERIMENTAL FARM, HI US')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Period of Record for each station\n",
    "sel = [Meas.station,\n",
    "       func.min(Meas.date), \n",
    "       func.max(Meas.date),\n",
    "       Sta.name]\n",
    "sta_daterange = session.query(*sel).\\\n",
    "    filter(Meas.station == Sta.station).\\\n",
    "    group_by(Meas.station).\\\n",
    "    order_by(Sta.name).all()\n",
    "sta_daterange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 12 months of precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('USC00519397', '2016-08-01', 0.08)\n",
      "('USC00519397', '2016-08-02', 0.05)\n",
      "('USC00519397', '2016-08-03', 0.0)\n",
      "('USC00519397', '2016-08-04', 0.04)\n",
      "('USC00519397', '2016-08-05', 0.01)\n",
      "('USC00519397', '2016-08-06', 0.0)\n",
      "('USC00519397', '2016-08-07', 0.39)\n",
      "('USC00519397', '2016-08-08', 0.02)\n",
      "('USC00519397', '2016-08-09', 0.0)\n",
      "('USC00519397', '2016-08-10', 0.0)\n",
      "\n",
      "Record count: 2281\n"
     ]
    }
   ],
   "source": [
    "# Retrieve 12 months of precipitation data spanning 2016-08-01 through 2017-07-31\n",
    "sel = [Meas.station,\n",
    "       Meas.date,\n",
    "       Meas.prcp]\n",
    "mindate = '2016-08-01'\n",
    "maxdate = '2017-07-31'\n",
    "\n",
    "sta_prcp = session.query(*sel).\\\n",
    "    filter(Meas.date >= mindate).\\\n",
    "    filter(Meas.date <= maxdate).all()\n",
    "\n",
    "for row in sta_prcp[0:10]:\n",
    "    print(row)\n",
    "print(f\"\\nRecord count: {len(sta_prcp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "USC00513117    365\n",
       "USC00514830    260\n",
       "USC00516128    331\n",
       "USC00517948     67\n",
       "USC00519281    365\n",
       "USC00519397    360\n",
       "USC00519523    319\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the query results as a Pandas DataFrame\n",
    "cols = ['Sta_ID', 'Date', 'Prec']\n",
    "df_sta_prcp = pd.DataFrame(sta_prcp, columns=cols)\n",
    "\n",
    "# Show count of NaN values for Prec\n",
    "display(df_sta_prcp['Prec'].isna().sum())\n",
    "\n",
    "# Get list of unique stations\n",
    "sta_prcp_list = sorted(list(df_sta_prcp['Sta_ID'].unique()))\n",
    "\n",
    "df_prcp = pd.pivot_table(df_sta_prcp, values='Prec', index='Date', columns='Sta_ID', aggfunc='first')\n",
    "df_prcp = df_prcp.rename_axis(None, axis=1)\n",
    "\n",
    "df_prcp.index = pd.to_datetime(df_prcp.index)\n",
    "display(df_prcp.index.dtype)\n",
    "df_prcp.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas Plotting with Matplotlib to plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to calcualte the summary statistics for the precipitation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a query to show how many stations are available in this dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most active stations? (i.e. what stations have the most rows)?\n",
    "# List the stations and the counts in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the station id from the previous query, calculate the lowest temperature recorded, \n",
    "# highest temperature recorded, and average temperature of the most active station?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "# Query the last 12 months of temperature observation data for this station and plot the results as a histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    \n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "\n",
    "# function usage example\n",
    "print(calc_temps('2012-02-28', '2012-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total amount of rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    \n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
